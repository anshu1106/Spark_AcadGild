 1. Execute map, flatMap, filter, reduceByKey, collect, count, reduce RDDs with an example in

Scala shell


val fruits = sc.parallelize(List("apple", "banana", "orange"))
flatmap-
val letters = fruits.flatMap(fruits=>fruits)
Output on collect action:
a
p
p
l
e
b
a
n
a
n
a
o
r
a
n
g
e

map-
val lettersMap = letters.map(i=>(i,1))

output on collect action:

(a,1)
(p,1)
(p,1)
(l,1)
(e,1)
(b,1)
(a,1)
(n,1)
(a,1)
(n,1)
(a,1)
(o,1)
(r,1)
(a,1)
(n,1)
(g,1)
(e,1)


reduceByKey-

scala> val groupByChar = lettersMap.reduceByKey(_+_)
groupByChar: org.apache.spark.rdd.RDD[(Char, Int)] = ShuffledRDD[12] at reduceByKey at <console>:39



collect-
groupByChar.collect.foreach(println)

(e,2)
(p,2)
(a,5)
(b,1)
(o,1)
(n,3)
(r,1)
(g,1)
(l,1)

count-

scala> groupByChar.count()
res12: Long = 9

reduce-


scala> val x = sc.parallelize(1 to 10, 2)
scala> val y = x.reduce((accum,n) => (accum + n)) 
y: Int = 55
